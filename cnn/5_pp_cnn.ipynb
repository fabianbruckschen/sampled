{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "dir_data = '../data/power_consumption/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import torch  # pytorch\n",
    "import numpy as np  # handling vectors and matrices\n",
    "from keras.models import load_model  # reload pretrained tf models\n",
    "from analysis_functions import (train_tf_model, pred_tf_model,\n",
    "                                train_pt_model, pred_pt_model)  # own functions\n",
    "from preproc_functions import list_combine  # own functions\n",
    "from nn_arguments import Arguments  # nn options\n",
    "from neural_nets import TFUNET, TFMNET, PTUNET, PTMNET  # own defined neural nets as classes\n",
    "\n",
    "# pysyft\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.tensors.interpreters import PointerTensor\n",
    "from syft.frameworks.torch.tensors.decorators import LoggingTensor\n",
    "hook = sy.TorchHook(torch)  # hooking pysyft into pytorch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### univariate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xu = np.load(dir_data+'train_Xu.npy')\n",
    "train_yu = np.load(dir_data+'train_yu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 14, 1)\n",
      "(988, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_Xu.shape)\n",
    "print(train_yu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "995 Observations for X days for 1 Variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multivariate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xm = np.load(dir_data+'train_Xm.npy')\n",
    "train_ym = np.load(dir_data+'train_ym.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 14, 8)\n",
      "(988, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_Xm.shape)\n",
    "print(train_ym.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "995 Observations for X days for 8 Variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Xu = np.load(dir_data+'test_Xs.npy')[:,:,:1]\n",
    "test_Xm = np.load(dir_data+'test_Xs.npy')\n",
    "test_y = np.load(dir_data+'test_ys.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 14, 1)\n",
      "(59, 14, 8)\n",
      "(59, 7)\n"
     ]
    }
   ],
   "source": [
    "print(test_Xu.shape)\n",
    "print(test_Xm.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "# overwrite timesteps depending on data\n",
    "args.n_timesteps = train_Xu.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/fb/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create net objects\n",
    "model_tfu = TFUNET(args.n_features_u, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)\n",
    "model_tfm = TFMNET(args.n_features_m, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model_tfu.load_weights(dir_data+'models/weights_tfu.h5')\n",
    "model_tfm.load_weights(dir_data+'models/weights_tfm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net objects\n",
    "model_ptu = PTUNET(args.n_features_u, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)\n",
    "model_ptm = PTMNET(args.n_features_m, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model_ptu.load_state_dict(torch.load(dir_data+'models/weights_ptu.pt'), strict=False)\n",
    "model_ptm.load_state_dict(torch.load(dir_data+'models/weights_ptm.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute Test data and model (all encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different parties\n",
    "client = sy.VirtualWorker(hook, id=\"client\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMPC works with integers so we need to convert floats to int via fix_precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(test_Xu).fix_precision().share(alice, bob, crypto_provider=crypto_provider)\n",
    "torch.tensor(test_y).fix_precision().share(alice, bob, crypto_provider=crypto_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ptu.fix_precision().share(alice, bob, crypto_provider=crypto_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(X)\n",
    "        pred = output.argmax(dim=1) \n",
    "        n_correct_priv += pred.eq(y.view_as(pred)).sum()\n",
    "        n_total += args.test_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
