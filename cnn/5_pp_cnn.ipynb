{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # handling vectors and matrices\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "from keras.models import load_model  # reload pretrained tf models\n",
    "from pnn_functions import (train_tf_model, pred_tf_model,\n",
    "                           train_pt_model, pred_pt_model)  # plain neural net functions\n",
    "from evaluation_functions import evaluate_forecasts  # evaluation functions\n",
    "from preproc_functions import list_combine  # own functions\n",
    "from nn_arguments import Arguments  # nn options\n",
    "from neural_nets import TFUNET, TFMNET, PTUNET, PTMNET  # own defined neural nets as classes\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "# pysyft\n",
    "import syft as sy\n",
    "import torch  # pytorch\n",
    "hook = sy.TorchHook(torch)  # hooking pysyft into pytorch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "dir_data = '../data/power_consumption/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need only the test-sets - Model is already trained\n",
    "#univariate\n",
    "test_Xu = np.load(dir_data+'test_Xs.npy')[:,:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mutlivariate\n",
    "test_Xm = np.load(dir_data+'test_Xs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Testset\n",
    "test_y = np.load(dir_data+'test_ys.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape Dimensions for Pytorch for Dataset\n",
    "test_Xu = torch.from_numpy(np.array(test_Xu.reshape(test_Xu.shape[0],\n",
    "                                                        test_Xu.shape[2],\n",
    "                                                        test_Xu.shape[1]),\n",
    "                                        dtype='float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Dimension Data\n",
    "test_Xu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Dimension Data\n",
    "test_Xm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Dimension Target\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data over DataLoader\n",
    "test_loaderXu = torch.utils.data.DataLoader(\n",
    "    np.load(dir_data+'test_Xs.npy')[:,:,:1])\n",
    "print (test_loaderXu)\n",
    "\n",
    "test_loadery = torch.utils.data.DataLoader(\n",
    "    np.load(dir_data+'test_ys.npy'))\n",
    "print (test_loadery)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "# overwrite timesteps depending on data\n",
    "args.n_timesteps = test_Xu.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Xu.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create net objects\n",
    "model_ptu = PTUNET(args.n_features_u, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)\n",
    "model_ptm = PTMNET(args.n_features_m, args.n_filters, args.n_timesteps, \n",
    "                   args.n_linear, args.n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model_ptu.load_state_dict(torch.load(dir_data+'models/weights_ptu.pt'), strict=False)\n",
    "model_ptm.load_state_dict(torch.load(dir_data+'models/weights_ptm.pt'), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute data and model between parties (all encrypted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different parties\n",
    "client = sy.VirtualWorker(hook, id=\"client\")\n",
    "bob = sy.VirtualWorker(hook, id=\"bob\")\n",
    "alice = sy.VirtualWorker(hook, id=\"alice\")\n",
    "charlie = sy.VirtualWorker(hook, id=\"charlie\")\n",
    "crypto_provider = sy.VirtualWorker(hook, id=\"crypto_provider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMPC works with integers so we need to convert floats to int via fix_precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share test data\n",
    "testData = torch.tensor(test_loaderXu).fix_precision().share(alice, bob, charlie, crypto_provider=crypto_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTarget = torch.tensor(test_loadery).fix_precision().share(alice, bob, charlie, crypto_provider=crypto_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test_loaderXu)[0].share()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataset\n",
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataset\n",
    "charlie._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# share model\n",
    "model_ptu.fix_precision().share(alice, bob, charlie, crypto_provider=crypto_provider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(args, model, data, target):\n",
    "    model.eval()\n",
    "    n_correct_priv = 0\n",
    "    n_total = 0\n",
    "    with torch.no_grad():\n",
    "       # for data, target in a, b:\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1) \n",
    "        n_correct_priv += pred.eq(target.view_as(pred)).sum()\n",
    "        n_total += args.test_batch_size\n",
    "        print (pred)\n",
    "        print(output)\n",
    "#The following test function performs the encrypted evaluation. The model weights, the data inputs, the prediction and the target used for scoring are all encrypted!\n",
    "\n",
    "# However as you can observe, the syntax is very similar to normal PyTorch testing! Nice!\n",
    "\n",
    "# The only thing we decrypt from the server side is the final score at the end of our 200 items batches to verify predictions were on average good.      \n",
    "        n_correct = n_correct_priv.copy().get().float_precision().long().item()\n",
    "\n",
    "        print('Test set: Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "            n_correct, n_total,\n",
    "            100. * n_correct / n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea 1: Without objectize the share to Virtual Worker\n",
    "test(args, model_ptu, test_loaderXu , test_loadery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Idea 1: with obejctize the share to Virtual Worker\n",
    "test(args, model_ptu, testData , testTarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End! --- Please ignore the following Code --- just not to loose this Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not nessecary now\n",
    "def test(modelptu, X, y):\n",
    "    modelptu.eval()\n",
    "    with torch.no_grad():\n",
    "        pred_1 = modelptu(X)\n",
    "        score, scores = evaluate_forecasts(y, pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dont do it! - Just for Testing\n",
    "bobs_model = modelu.copy().send(bob)\n",
    "alices_model = modelu.copy().send(alice)\n",
    "charlie_model = modelu.copy().send(charlie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
