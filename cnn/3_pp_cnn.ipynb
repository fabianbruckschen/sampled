{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Privacy-Preserving CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "dir_data = '../data/power_consumption/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING:root:Torch was already hooked... skipping hooking process\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd  # data mangling and transforming\n",
    "import numpy as np  # handling vectors and matrices\n",
    "import matplotlib.pyplot as plt  # plotting\n",
    "from sklearn.metrics import mean_squared_error  # MSE error metric\n",
    "from analysis_functions import (evaluate_forecasts, train_tf_model, pred_tf_model,\n",
    "                                train_pt_model, pred_pt_model)  # own functions\n",
    "from preproc_functions import list_combine  # own functions\n",
    "from neural_nets import UNet, MNet  # own defined neural nets as classes\n",
    "\n",
    "# pysyft\n",
    "import syft as sy\n",
    "from syft.frameworks.torch.tensors.interpreters import PointerTensor\n",
    "from syft.frameworks.torch.tensors.decorators import LoggingTensor\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "hook = sy.TorchHook(torch)  # hooking pysyft into pytorch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### univariate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xu = np.load(dir_data+'train_Xu.npy')\n",
    "train_yu = np.load(dir_data+'train_yu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 14, 1)\n",
      "(988, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_Xu.shape)\n",
    "print(train_yu.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "995 Observations for X days for 1 Variable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multivariate training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Xm = np.load(dir_data+'train_Xm.npy')\n",
    "train_ym = np.load(dir_data+'train_ym.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 14, 8)\n",
      "(988, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_Xm.shape)\n",
    "print(train_ym.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "995 Observations for X days for 8 Variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Xu = np.load(dir_data+'test_Xs.npy')[:,:,:1]\n",
    "test_Xm = np.load(dir_data+'test_Xs.npy')\n",
    "test_y = np.load(dir_data+'test_ys.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 14, 1)\n",
      "(59, 14, 8)\n",
      "(59, 7)\n"
     ]
    }
   ],
   "source": [
    "print(test_Xu.shape)\n",
    "print(test_Xm.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (conv1): Conv1d(1, 16, kernel_size=(3,), stride=(1,))\n",
       "  (l1): Linear(in_features=96, out_features=10, bias=True)\n",
       "  (l2): Linear(in_features=10, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch\n",
    "model_ptu = torch.load(dir_data+'models/model_ptu.pt')\n",
    "model_ptu.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_ptu, rmse_ptu = pred_pt_model(test_Xu, test_y, model_ptu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net hyper parameters\n",
    "epochs_u = 20\n",
    "batch_size_u = 4\n",
    "epochs_m = 70\n",
    "batch_size_m = 16\n",
    "lr = 0.001\n",
    "n_filters = 16\n",
    "n_linear = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "n_timesteps = train_Xu.shape[1] \n",
    "n_features_u = train_Xu.shape[2]\n",
    "n_features_m = train_Xm.shape[2]\n",
    "n_outputs = train_yu.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build univariate model\n",
    "model_tfu = Sequential()\n",
    "model_tfu.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu', \n",
    "                     input_shape=(n_timesteps, n_features_u)))\n",
    "model_tfu.add(MaxPooling1D(pool_size=2))\n",
    "model_tfu.add(Flatten())\n",
    "model_tfu.add(Dense(n_linear, activation='relu'))\n",
    "model_tfu.add(Dense(n_outputs))\n",
    "model_tfu.compile(loss='mse', optimizer=Adam(lr=lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multivariate model\n",
    "model_tfm = Sequential()\n",
    "model_tfm.add(Conv1D(filters=n_filters*2, kernel_size=3, activation='relu', \n",
    "                     input_shape=(n_timesteps, n_features_m)))\n",
    "if n_timesteps >= 14:\n",
    "    model_tfm.add(Conv1D(filters=n_filters*2, kernel_size=3, activation='relu'))\n",
    "    model_tfm.add(MaxPooling1D(pool_size=2))\n",
    "model_tfm.add(Conv1D(filters=n_filters, kernel_size=3, activation='relu'))\n",
    "model_tfm.add(MaxPooling1D(pool_size=2))\n",
    "model_tfm.add(Flatten())\n",
    "model_tfm.add(Dense(n_linear*10, activation='relu'))\n",
    "model_tfm.add(Dense(n_outputs))\n",
    "model_tfm.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define univariate class\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_features_u, n_filters, 3, stride=1)\n",
    "        self.aps = int(np.floor((n_timesteps-3+1)/2))\n",
    "        self.l1 = nn.Linear(n_filters*self.aps, n_linear)\n",
    "        self.l2 = nn.Linear(n_linear, n_outputs)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = x.view(-1, n_filters*self.aps) # flatten\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define multivariate class\n",
    "class MNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_features_m, n_filters*2, 3, stride=1)\n",
    "        self.conv2 = nn.Conv1d(n_filters*2, n_filters*2, 3, stride=1)\n",
    "        self.conv3 = nn.Conv1d(n_filters*2, n_filters, 3, stride=1)\n",
    "        self.aps = int(np.floor((n_timesteps-3+1)/4))\n",
    "        self.l1 = nn.Linear(n_filters, n_linear*10)\n",
    "        self.l2 = nn.Linear(n_linear*10, n_outputs)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        if n_timesteps >= 14:\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = x.view(-1, n_filters) # flatten\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions & RMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfu = train_tf_model(train_Xu, train_yu, model_tfu,\n",
    "                           epochs=epochs_u, batch_size=batch_size_u)\n",
    "y_tfu, rmse_tfu = pred_tf_model(test_Xu, test_y, model_tfu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tfm = train_tf_model(train_Xm, train_ym, model_tfm,\n",
    "                           epochs=epochs_m, batch_size=batch_size_m)\n",
    "y_tfm, rmse_tfm = pred_tf_model(test_Xm, test_y, model_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ptu = train_pt_model(train_Xu, train_yu, UNet(),\n",
    "                           batch_size_u, epochs_u, lr,\n",
    "                           n_timesteps, n_features_u, n_outputs)\n",
    "y_ptu, rmse_ptu = pred_pt_model(test_Xu, test_y, model_ptu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ptm = train_pt_model(train_Xm, train_ym, MNet(),\n",
    "                           batch_size_m, epochs_m, lr,\n",
    "                           n_timesteps, n_features_m, n_outputs)\n",
    "y_ptm, rmse_ptm = pred_pt_model(test_Xm, test_y, model_ptm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graph per weekday**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores\n",
    "days = ['mon', 'tue', 'wed', 'thr', 'fri', 'sat', 'sun']\n",
    "plt.plot(days, rmse_tfu[1], marker='o', label='tensorflow univariate')\n",
    "plt.plot(days, rmse_ptu[1], marker='o', label='pytorch univariate')\n",
    "plt.plot(days, rmse_tfm[1], marker='o', label='tensorflow multivariate')\n",
    "plt.plot(days, rmse_ptm[1], marker='o', label='pytorch multivariate')\n",
    "plt.legend()\n",
    "plt.title('RMSE for the next standard week given %s input days' % n_timesteps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**save rmse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ['rmse']\n",
    "l2 = ['_tf', '_pt']\n",
    "l3 = ['m', 'u']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = list_combine(list_combine(l1,l2), l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in file_names:\n",
    "    np.save(dir_data+item, eval(item)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
