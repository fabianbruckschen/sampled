{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plain-Text CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "dir_data = '../data/power_consumption/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  # data mangling and transforming\n",
    "import numpy as np  # handling vectors and matrices\n",
    "from sklearn.metrics import mean_squared_error  # MSE error metric\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.load(dir_data+'train_Xu.npy')\n",
    "train_y = np.load(dir_data+'train_yu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use only the next day\n",
    "# train_y = train_y[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994, 7, 1)\n",
      "(994, 7)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "994 Observations for 7 days for 1 Variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.load(dir_data+'test_Xu.npy')\n",
    "test_y = np.load(dir_data+'test_yu.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(413, 7, 1)\n",
      "(413, 7)\n"
     ]
    }
   ],
   "source": [
    "print(test_X.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net hyper parameters\n",
    "epochs = 20\n",
    "batch_size = 4\n",
    "lr = 0.001\n",
    "# dimensions\n",
    "n_timesteps = train_X.shape[1] \n",
    "n_features = train_X.shape[2]\n",
    "n_outputs = train_y.shape[1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tf_model(train_X, train_y,\n",
    "                   batch_size, epochs, lr,\n",
    "                   n_timesteps, n_features, n_outputs):\n",
    "    \n",
    "    # build model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                     input_shape=(n_timesteps,n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(n_outputs))\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=lr))\n",
    "    \n",
    "    # fit the model\n",
    "    model.fit(train_X, train_y, \n",
    "              epochs=epochs, batch_size=batch_size,\n",
    "              verbose=0)\n",
    "    \n",
    "    # return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_tf_model(test_X, test_y, model):\n",
    "    # create predictions\n",
    "    preds = model.predict(test_X)\n",
    "    \n",
    "    # print RMSE\n",
    "    rmse = round(np.sqrt(mean_squared_error(test_y, preds)), 2)\n",
    "    print('RMSE for TF model: %s!'%rmse)\n",
    "    \n",
    "    # return predictions and RMSE\n",
    "    return preds, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define class\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_features, 16, 3, stride=1)\n",
    "        self.l1 = nn.Linear(16*2, 10)\n",
    "        self.l2 = nn.Linear(10, n_outputs)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool1d(x, kernel_size=2)\n",
    "        x = x.view(-1, 16*2) # flatten\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pt_model(train_X, train_y,\n",
    "                   batch_size, epochs, lr,\n",
    "                   n_timesteps, n_features, n_outputs):\n",
    "    \n",
    "    # transform data to tensors (reshape dimensions of X)\n",
    "    train_X = torch.from_numpy(np.array(train_X.reshape(train_X.shape[0], \n",
    "                                                        train_X.shape[2], \n",
    "                                                        train_X.shape[1]), dtype='float32'))\n",
    "    train_y = torch.from_numpy(np.array(train_y, dtype='float32'))\n",
    "    \n",
    "    \n",
    "    # create dataloader\n",
    "    train_Xy = DataLoader(TensorDataset(train_X, train_y), \n",
    "                          batch_size, \n",
    "                          shuffle=True)\n",
    "    \n",
    "    # build model\n",
    "    model = Net()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = F.mse_loss\n",
    "    \n",
    "    # fit the model\n",
    "    def fit(df, num_epochs, model, loss_fn, opt):\n",
    "        for epoch in range(num_epochs):\n",
    "            for xb,yb in df:\n",
    "                # Generate predictions\n",
    "                pred = model(xb)\n",
    "                loss = loss_fn(pred, yb)\n",
    "                # Perform gradient descent\n",
    "                opt.zero_grad()\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            \n",
    "    fit(train_Xy, epochs, model, loss_fn, opt)\n",
    "    \n",
    "    # return model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_pt_model(test_X, test_y, model):\n",
    "    \n",
    "    # transform data to tensors (reshape dimensions of X)\n",
    "    test_X = torch.from_numpy(np.array(test_X.reshape(test_X.shape[0], \n",
    "                                                      test_X.shape[2], \n",
    "                                                      test_X.shape[1]), dtype='float32'))\n",
    "    \n",
    "    # create predictions\n",
    "    preds = model(test_X).data.numpy()\n",
    "\n",
    "    # print RMSE\n",
    "    rmse = round(np.sqrt(mean_squared_error(test_y, preds)), 2)\n",
    "    print('RMSE for PT model: %s!'%rmse)\n",
    "    \n",
    "    # return predictions and RMSE\n",
    "    return preds, rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for TF model: 400.31!\n"
     ]
    }
   ],
   "source": [
    "# tensorflow\n",
    "model_tf = train_tf_model(train_X, train_y, \n",
    "                          batch_size, epochs, lr,\n",
    "                          n_timesteps, n_features, n_outputs)\n",
    "y_tf, rmse_tf = pred_tf_model(test_X, test_y, model_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for PT model: 395.36!\n"
     ]
    }
   ],
   "source": [
    "# pytorch\n",
    "model_pt = train_pt_model(train_X, train_y,\n",
    "                          batch_size, epochs, lr,\n",
    "                          n_timesteps, n_features, n_outputs)\n",
    "y_pt, rmse_pt = pred_pt_model(test_X, test_y, model_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
